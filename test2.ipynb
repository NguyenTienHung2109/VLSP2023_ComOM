{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: The lens is n't too great either , but it only shows it 's faults when it 's pushed to it 's extremes . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n",
      "Sentence: The battery life is consistent with all of the Nikon DLSR models - it lasts forever . \n",
      "Label: 1\n",
      "Final Label: ['[[7&&all 8&&of 9&&the 10&&Nikon 11&&DLSR 12&&models];[7&&all 8&&of 9&&the 10&&Nikon 11&&DLSR 12&&models];[2&&battery 3&&life];[5&&consistent];[0]]']\n",
      "\n",
      "Sentence: The lens is n't too great either , but it only shows it 's faults when it 's pushed to it 's extremes . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n",
      "Sentence: This camera is ready to go when I am . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n",
      "Sentence: It takes very decent pictures in low light basketball gyms without the flash on . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n",
      "Sentence: Besides this is digital . . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n",
      "Sentence: I finally found the Black body for $ 862 from my search on Shopping.com . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n",
      "Sentence: And sure it 's no Canon XL-2 video camera but with 30fps VGA ( 640x480 ) video with audio moving pictures are smooth . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n",
      "Sentence: Both iXUS 40 and 65 are Made in Japan . \n",
      "Label: 1\n",
      "Final Label: ['[[2&&iXUS 3&&40];[5&&65];[];[7&&Made 8&&in 9&&Japan];[0]]']\n",
      "\n",
      "Sentence: In fact it is remarkably similar to manual cameras of old , and in my opinion that is a high complement . \n",
      "Label: 1\n",
      "Final Label: ['[[3&&it];[8&&manual 9&&cameras 10&&of 11&&old];[];[6&&similar];[0]]']\n",
      "\n",
      "Sentence: The issues of redeye remain . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n",
      "Sentence: I chose this camera over even those models because it is a perfect fit for me and I think it is a perfect fit for anyone no matter what you are looking for in a camera . \n",
      "Label: 1\n",
      "Final Label: ['[[3&&this 4&&camera];[6&&even 7&&those 8&&models];[];[5&&over];[1]]']\n",
      "\n",
      "Sentence: I knew what I wanted - a camera that took great ( clear , focused , lit well , properly white balanced ) photos in all lighting conditions , had a long lasting battery , image stabilization , had enough options that I could fine tune my photography to the extent that I knew how , and took decent videos . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n",
      "Sentence: Since I had a film SLR from years ago and then bought a Sony point-and-shoot , the Rebel was n't hard to learn . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n",
      "Sentence: In truth , the focus system is good : better than most of the systems that I 've seen . \n",
      "Label: 1\n",
      "Final Label: ['[[5&&focus 6&&system];[12&&most 13&&of 14&&the 15&&systems];[];[10&&better];[1]]']\n",
      "\n",
      "Sentence: For self-photographers - A note on the wireless remote The wireless remote for the 5D is significantly more expensive and less portable than that of the 350D . \n",
      "Label: 1\n",
      "Final Label: ['[[11&&wireless 12&&remote 13&&for 14&&the 15&&5D];[24&&that 25&&of 26&&the 27&&350D];[];[21&&less 22&&portable];[-1]]', '[[11&&wireless 12&&remote 13&&for 14&&the 15&&5D];[24&&that 25&&of 26&&the 27&&350D];[];[18&&more 19&&expensive];[-1]]']\n",
      "\n",
      "Sentence: Other significant improvements vs. 20D , can be found in the tech sheet . \n",
      "Label: 1\n",
      "Final Label: ['[[];[5&&20D];[];[3&&improvements];[-1]]']\n",
      "\n",
      "Sentence: The features in this camera are exceptional and the buttons are well placed . \n",
      "Label: 0\n",
      "Final Label: ['[[];[];[];[];[]]']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def split_string(line, split_symbol):\n",
    "    \"\"\"\n",
    "    :param line: a string need be split\n",
    "    :param split_symbol: a string: split symbol\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return list(filter(None, line.split(split_symbol)))\n",
    "\n",
    "\n",
    "def read_standard_file(data):\n",
    "    \"\"\"\n",
    "    :param path:\n",
    "    :return: sent_col, sent_label_col and label_col\n",
    "    \"\"\"\n",
    "    sent_col, sent_label_col, final_label_col = [], [], []\n",
    "    last_sentence = \"\"\n",
    "    data = data.split('\\n')\n",
    "    for line in data:\n",
    "        line = line.rstrip('\\n')\n",
    "        # \"[[\" denote the begin of sequence label.\n",
    "        if line[:2] == \"[[\":\n",
    "            label_col.append(line)\n",
    "\n",
    "        else:\n",
    "            \n",
    "            if last_sentence != \"\":\n",
    "                cur_sent, cur_sent_label = split_string(last_sentence, \"\\t\")\n",
    "                sent_col.append(cur_sent)\n",
    "                sent_label_col.append(int(cur_sent_label))\n",
    "                final_label_col.append(label_col)\n",
    "\n",
    "            last_sentence = clear_string(line, replace_symbol={u'\\u3000': u\"\"})\n",
    "            label_col = []\n",
    "\n",
    "\n",
    "    return sent_col, sent_label_col, final_label_col\n",
    "\n",
    "def clear_string(line, strip_symbol=None, replace_symbol=None):\n",
    "    \"\"\"\n",
    "    :param line: a string\n",
    "    :param strip_symbol:\n",
    "    :param replace_symbol: a list of special symbol, need replace.\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if strip_symbol is not None:\n",
    "        for sym in strip_symbol:\n",
    "            line = line.strip(sym)\n",
    "\n",
    "    if replace_symbol is not None:\n",
    "        for sym in replace_symbol:\n",
    "            line = line.replace(sym, \"\")\n",
    "\n",
    "    return line\n",
    "\n",
    "# Example data\n",
    "data = \"\"\"\n",
    "The lens is n't too great either , but it only shows it 's faults when it 's pushed to it 's extremes . \t0\n",
    "[[];[];[];[];[]]\n",
    "The battery life is consistent with all of the Nikon DLSR models - it lasts forever . \t1\n",
    "[[7&&all 8&&of 9&&the 10&&Nikon 11&&DLSR 12&&models];[7&&all 8&&of 9&&the 10&&Nikon 11&&DLSR 12&&models];[2&&battery 3&&life];[5&&consistent];[0]]\n",
    "The lens is n't too great either , but it only shows it 's faults when it 's pushed to it 's extremes . \t0\n",
    "[[];[];[];[];[]]\n",
    "This camera is ready to go when I am . \t0\n",
    "[[];[];[];[];[]]\n",
    "It takes very decent pictures in low light basketball gyms without the flash on . \t0\n",
    "[[];[];[];[];[]]\n",
    "Besides this is digital . . \t0\n",
    "[[];[];[];[];[]]\n",
    "I finally found the Black body for $ 862 from my search on Shopping.com . \t0\n",
    "[[];[];[];[];[]]\n",
    "And sure it 's no Canon XL-2 video camera but with 30fps VGA ( 640x480 ) video with audio moving pictures are smooth . \t0\n",
    "[[];[];[];[];[]]\n",
    "Both iXUS 40 and 65 are Made in Japan . \t1\n",
    "[[2&&iXUS 3&&40];[5&&65];[];[7&&Made 8&&in 9&&Japan];[0]]\n",
    "In fact it is remarkably similar to manual cameras of old , and in my opinion that is a high complement . \t1\n",
    "[[3&&it];[8&&manual 9&&cameras 10&&of 11&&old];[];[6&&similar];[0]]\n",
    "The issues of redeye remain . \t0\n",
    "[[];[];[];[];[]]\n",
    "I chose this camera over even those models because it is a perfect fit for me and I think it is a perfect fit for anyone no matter what you are looking for in a camera . \t1\n",
    "[[3&&this 4&&camera];[6&&even 7&&those 8&&models];[];[5&&over];[1]]\n",
    "I knew what I wanted - a camera that took great ( clear , focused , lit well , properly white balanced ) photos in all lighting conditions , had a long lasting battery , image stabilization , had enough options that I could fine tune my photography to the extent that I knew how , and took decent videos . \t0\n",
    "[[];[];[];[];[]]\n",
    "Since I had a film SLR from years ago and then bought a Sony point-and-shoot , the Rebel was n't hard to learn . \t0\n",
    "[[];[];[];[];[]]\n",
    "In truth , the focus system is good : better than most of the systems that I 've seen . \t1\n",
    "[[5&&focus 6&&system];[12&&most 13&&of 14&&the 15&&systems];[];[10&&better];[1]]\n",
    "For self-photographers - A note on the wireless remote The wireless remote for the 5D is significantly more expensive and less portable than that of the 350D . \t1\n",
    "[[11&&wireless 12&&remote 13&&for 14&&the 15&&5D];[24&&that 25&&of 26&&the 27&&350D];[];[21&&less 22&&portable];[-1]]\n",
    "[[11&&wireless 12&&remote 13&&for 14&&the 15&&5D];[24&&that 25&&of 26&&the 27&&350D];[];[18&&more 19&&expensive];[-1]]\n",
    "Other significant improvements vs. 20D , can be found in the tech sheet . \t1\n",
    "[[];[5&&20D];[];[3&&improvements];[-1]]\n",
    "The features in this camera are exceptional and the buttons are well placed . \t0\n",
    "[[];[];[];[];[]]\n",
    "\"\"\"\n",
    "\n",
    "sent_col, sent_label_col, final_label_col = read_standard_file(data)\n",
    "\n",
    "# Print the results\n",
    "for sent, label, final_label in zip(sent_col, sent_label_col, final_label_col):\n",
    "    print(\"Sentence:\", sent)\n",
    "    print(\"Label:\", label)\n",
    "    print(\"Final Label:\", final_label)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]], [[(6, 12), (6, 12), (1, 3), (4, 5), (0, 0)]], [[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]], [[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]], [[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]], [[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]], [[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]], [[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]], [[(1, 3), (4, 5), (-1, -1), (6, 9), (0, 0)]], [[(2, 3), (7, 11), (-1, -1), (5, 6), (0, 0)]], [[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]], [[(2, 4), (5, 8), (-1, -1), (4, 5), (1, 1)]], [[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]], [[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]], [[(4, 6), (11, 15), (-1, -1), (9, 10), (1, 1)]], [[(10, 15), (23, 27), (-1, -1), (20, 22), (-1, -1)], [(10, 15), (23, 27), (-1, -1), (17, 19), (-1, -1)]], [[(-1, -1), (4, 5), (-1, -1), (2, 3), (-1, -1)]], [[(-1, -1), (-1, -1), (-1, -1), (-1, -1), (-1, -1)]]]\n"
     ]
    }
   ],
   "source": [
    "class LabelParser(object):\n",
    "    def __init__(self, label_col, elem_col, intermittent=False):\n",
    "        \"\"\"\n",
    "        :param label_col:\n",
    "        :param elem_col: [\"entity_1\", \"entity_2\", \"aspect\", \"result\"]\n",
    "        :param intermittent: True denote \"result\" using intermittent representation\n",
    "        \"\"\"\n",
    "        self.label_col = label_col\n",
    "        self.elem_col = elem_col\n",
    "        self.intermittent = intermittent\n",
    "\n",
    "    def parse_sequence_label(self, split_symbol=\"&\", sent_col=None, file_type=\"vn\"):\n",
    "        \"\"\"\n",
    "        :param split_symbol:\n",
    "        :param sent_col:\n",
    "        :param file_type\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        null_label = \"[[];[];[];[];[]]\"\n",
    "        tuple_pair_col, elem_representation_col = [], []\n",
    "\n",
    "        for index in range(len(self.label_col)):\n",
    "            # For non-comparative sentences' label.\n",
    "            if self.label_col[index][0] == null_label:\n",
    "                tuple_pair_col.append([[(-1, -1)] * 5])\n",
    "                elem_representation_col.append(self.init_label_representation())\n",
    "\n",
    "            else:\n",
    "                global_elem_col = self.init_label_representation()\n",
    "\n",
    "                sequence_tuple_pair = []\n",
    "                for pair_index in range(len(self.label_col[index])):\n",
    "                    global_elem_col, cur_tuple_pair = self.parse_each_pair_label(\n",
    "                        self.label_col[index][pair_index], global_elem_col, split_symbol, sent_col[index], file_type\n",
    "                    )\n",
    "                    sequence_tuple_pair.append(cur_tuple_pair)\n",
    "\n",
    "                tuple_pair_col.append(sequence_tuple_pair)\n",
    "                elem_representation_col.append(global_elem_col)\n",
    "\n",
    "        return elem_representation_col, tuple_pair_col\n",
    "\n",
    "    def parse_each_pair_label(self, sequence_label, global_elem_col, split_symbol, sent=None, file_type=\"vn\"):\n",
    "        \"\"\"\n",
    "        :param sequence_label:\n",
    "        :param global_elem_col:\n",
    "        :param split_symbol:\n",
    "        :param sent:\n",
    "        :param file_type:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        elem_representation = split_string(sequence_label[1:-1], \";\")\n",
    "        \n",
    "        tuple_pair_representation, result_elem = [], []\n",
    "        for elem_index, each_elem in enumerate(elem_representation):\n",
    "        \n",
    "            if elem_index == 3 and each_elem == \"[]\":\n",
    "                print(elem_representation)\n",
    "            if self.intermittent:\n",
    "                seg_elem_col = split_string(each_elem[1: -1], \" , \")\n",
    "\n",
    "            else:\n",
    "                seg_elem_col = [each_elem[1: -1]] if each_elem[1:-1] != \"\" else []\n",
    "            elem_tuple = ()\n",
    "\n",
    "            # not polarity\n",
    "            if elem_index != len(elem_representation) - 1:\n",
    "                \n",
    "                for each_seg_elem in seg_elem_col:\n",
    "                    \n",
    "                    number_char_col = split_string(each_seg_elem, \" \")\n",
    "\n",
    "                    if file_type == \"cn\":\n",
    "                        s_index = int(split_string(number_char_col[0], split_symbol)[0])\n",
    "                        e_index = int(split_string(number_char_col[-1], split_symbol)[0]) + 1\n",
    "                    else:\n",
    "                        s_index = int(split_string(number_char_col[0], split_symbol)[0]) - 1\n",
    "                        e_index = int(split_string(number_char_col[-1], split_symbol)[0])\n",
    "\n",
    "                    elem_tuple += (s_index, e_index)\n",
    "\n",
    "                    if self.elem_col[elem_index] == \"result\":\n",
    "                        result_elem += [s_index, e_index]\n",
    "\n",
    "                    # [check sentence and label position]\n",
    "                    # if sent is not None:\n",
    "                    #     cur_elem_str = self.get_sub_elem(number_char_col, split_symbol)\n",
    "                    #\n",
    "                    #     if cur_elem_str != sent[s_index: e_index]:\n",
    "                    #         print(\"----------------------------\")\n",
    "                    #         print(cur_elem_str)\n",
    "                    #         print(sent[s_index: e_index])\n",
    "                    #         print(s_index, e_index)\n",
    "                    #         print(number_char_col)\n",
    "                    #         print(\"----------------------------\")\n",
    "\n",
    "            else:\n",
    "                polarity = int(seg_elem_col[0])\n",
    "                \n",
    "                elem_tuple += (polarity, polarity)\n",
    "\n",
    "                # 针对英文中可能存在空的情况\n",
    "                if len(result_elem) == 0:\n",
    "                    result_elem = [-1, -1]\n",
    "\n",
    "                result_elem.append(polarity)\n",
    "\n",
    "            elem_tuple = (-1, -1) if len(elem_tuple) == 0 else elem_tuple\n",
    "            tuple_pair_representation.append(elem_tuple)\n",
    "\n",
    "            if elem_index < 3 and elem_tuple != (-1, -1):\n",
    "                global_elem_col[self.elem_col[elem_index]].add(elem_tuple)\n",
    "\n",
    "        global_elem_col[\"result\"].add(tuple(result_elem))\n",
    "\n",
    "        return global_elem_col, tuple_pair_representation\n",
    "\n",
    "    @staticmethod\n",
    "    def get_sub_elem(number_char_col, split_symbol):\n",
    "        \"\"\"\n",
    "        :param number_char_col:\n",
    "        :param split_symbol:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        elem_str = \"\"\n",
    "        for num_char in number_char_col:\n",
    "            elem_str += split_string(num_char, split_symbol)[1]\n",
    "\n",
    "        return elem_str\n",
    "\n",
    "    def init_label_representation(self):\n",
    "        return {key: set() for key in self.elem_col}\n",
    "    \n",
    "sent_col, sent_label_col, label_col = read_standard_file(data)\n",
    "LP = LabelParser(label_col, [\"entity_1\", \"entity_2\", \"aspect\", \"result\"])\n",
    "label_col, tuple_pair_col = LP.parse_sequence_label(\"&\", sent_col)\n",
    "print(tuple_pair_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at vinai/phobert-base-v2 and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class phobertFeature(object):\n",
    "    def __init__(self, sentences):\n",
    "        \"\"\"\n",
    "        :param sentences: a list of sentence, [sentence1, sentence2......]\n",
    "        :param stanford_path: nlp stanford core path\n",
    "        :param lang: denote which language sentences need to process\n",
    "        \"\"\"\n",
    "        self.phobert = AutoModel.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/phobert-base-v2\")\n",
    "\n",
    "        # using set to store label type\n",
    "        self.sentences_col = sentences\n",
    "        self.pos_dict, self.pos_index = {\"PAD\": 0}, 1\n",
    "        self.dep_label_dict, self.dep_label_index = {}, 1\n",
    "        self.vocab = {}\n",
    "\n",
    "        # store the maximum length of sequence\n",
    "        self.max_len = -1\n",
    "\n",
    "    def get_tokenizer(self):\n",
    "        \"\"\"\n",
    "        :return: a list of token by stanford tokenizer\n",
    "        \"\"\"\n",
    "        input_tokens = []\n",
    "        for i in range(len(self.sentences_col)):\n",
    "            input_ids = torch.tensor([self.tokenizer.encode(self.sentences_col[i])])\n",
    "\n",
    "            with torch.no_grad():\n",
    "                features = self.phobert(input_ids)  # Models outputs are now tuples\n",
    "            input_tokens.append(features)\n",
    "\n",
    "        return input_tokens\n",
    "\n",
    "def get_max_token_length(token_col):\n",
    "    \"\"\"\n",
    "    :param token_col: a list of list token. shape: [n, each_token_num]\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    token_len = -1\n",
    "    for index in range(len(token_col)):\n",
    "        token_len = max(token_len, len(token_col[index]))\n",
    "    return token_len\n",
    "\n",
    "data_dict = {}    \n",
    "sf = phobertFeature(\"chúng tôi muốn đánh nhau với gấu\")\n",
    "data_dict['standard_token'] = sf.get_tokenizer()\n",
    "a = get_max_token_length(data_dict['standard_token'])\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
